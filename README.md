# Probabilistic Linear Discriminant Analysis

__Disclaimer__

This model was written for
 an [Explainable Artificial Intelligence (XAI) project](
     http://shaftolab.com/people.html), 
 so it stores a bunch of parameters in memory that 
 are not necessary for simple classification problems.

The model parameters are estimated via empirical Bayes.

__Paper Citation__

[Ioffe S. (2006) Probabilistic Linear Discriminant Analysis. 
 In: Leonardis A., Bischof H., Pinz A. (eds) Computer Vision â€“ ECCV 2006. 
 ECCV 2006.](
 https://link.springer.com/chapter/10.1007/11744085_41)

__Dependencies__

You can use this package in 3 ways.


1. If you don't use virtual environments:
    `pip install PATH/TO/PARENT/DIRECTORY/plda`.
   However, in most cases you really should use virtual environments, 
     especially if you want your work to be reproducible with minimal effort.
2. If you already have a virtual environment, 
     activate your environment and _then_ run 
    `pip install PATH/TO/PARENT/DIRECTORY/plda`.
3. If you already have Conda installed via [Anaconda or Miniconda](
    https://docs.conda.io/projects/conda/en/latest/), 
    then you can run the following to automatically create a virtual 
    environment called `plda` that will have this package installed.

    ``` shell
    conda env create -f environment.yml -n plda  # plda is the environment name.
    ```

Otherwise, see [environment.yml](./environment.yml).

__Usage__
1. If you installed this package in a virtual environment, 
    activate that environment first.
2. Add `import plda` to your code.

## Demo with MNIST Handwritten Digits Data
See [mnist_demo/mnist_demo.ipynb](
     ./mnist_demo/mnist_demo.ipynb).
It shows you have to 
1. estimate the model parameters, 
2. classify data points,
3. determine whether two points are from the same category or not, and
4. how to extract LDA features from your data.

- For classification, 
   the model automatically preprocesses your data, 
   but with the default preprocessing setting, 
   it will overfit small training datasets.
- If you run into this issue, 
   one way to address it is to reduce the number of principal components 
   present in the preprocessed data (example is in the demo).

## Testing
If you created the Conda environment with the name `plda`, 
 activate it with the following.
``` shell
conda activate plda  # If `plda` is the name you gave the Conda environment.
```

To run all tests (~120 seconds with ~60 CPU cores), use the following.
``` shell
pytest plda/  # README.md should be in this directory.
```

To run a particular test file, run one of the following.
``` shell
pytest plda/tests/test_model/test_model_units.py  # ~.66s for me.
pytest plda/tests/test_model/test_model_integration.py  # ~1.0s for me.
pytest plda/tests/test_model/test_model_inference.py  #  ~80.6s for me.

pytest plda/tests/test_optimizer/test_optimizer_units.py  # ~.59s for me.
pytest plda/tests/test_optimizer/test_optimizer_integration.py  # ~.78s.
pytest plda/tests/test_optimizer/test_optimizer_inference.py  # ~25.3s for me.

pytest plda/tests/test_classifier/test_classifier_integration.py  # ~.69s.
```

Once you finish running the tests, 
 remove all the `__pycache__/` folders generated by pytest with the following.
``` shell
py3clean plda/*  # This README.md should be in here.
```

Finally, if you are done working with the model and test code, 
 deactivate the Conda environment.
``` shell
conda deactivate  # You can run this from any directory.
```
